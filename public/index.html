<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Revolt Voice Bot - Auto Listen</title>
</head>
<body>
  <h1>ðŸŽ¤ Revolt Voice Bot - Auto Listen</h1>
  <p id="status">Click start to begin</p>
  <h2>Transcription:</h2>
  <div id="transcription" style="border:1px solid #ccc; padding:10px; min-height:40px;">
    Waiting for text...
  </div>

  <button id="startBtn">Start</button>
  <button id="stopBtn">Stop</button>

  <script>
    let ws;
    let mediaRecorder;
    let audioStream;
    let currentUtterance = null;
    let audioContext, analyser, source, dataArray;
    let silenceTimer;
    const silenceThreshold = 0.01; // adjust for mic sensitivity
    const silenceDelay = 1200; // ms of silence before stop

    // ðŸ”Š Speak text with browser TTS
    function speakText(text) {
      if ('speechSynthesis' in window) {
        speechSynthesis.cancel();

        currentUtterance = new SpeechSynthesisUtterance(text);
        currentUtterance.lang = "en-US";
        currentUtterance.rate = 1.0;
        currentUtterance.pitch = 1.0;

        currentUtterance.onend = () => {
          console.log("âœ… Speech ended, restart listening");
          startListening(); // restart mic after bot finishes
        };

        speechSynthesis.speak(currentUtterance);
      }
    }

    function detectSilence() {
      analyser.getFloatTimeDomainData(dataArray);
      let sumSquares = 0.0;
      for (const x of dataArray) sumSquares += x * x;
      const rms = Math.sqrt(sumSquares / dataArray.length);

      if (rms < silenceThreshold) {
        if (!silenceTimer) {
          silenceTimer = setTimeout(stopListening, silenceDelay);
        }
      } else {
        if (silenceTimer) {
          clearTimeout(silenceTimer);
          silenceTimer = null;
        }
      }

      requestAnimationFrame(detectSilence);
    }

    async function startListening() {
      if (mediaRecorder && mediaRecorder.state === "recording") return;

      ws = new WebSocket("ws://localhost:3000");

      ws.onopen = async () => {
        document.getElementById("status").textContent = "ðŸŽ™ï¸ Listening...";
        console.log("WS connected");

        audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(audioStream, { mimeType: "audio/webm;codecs=opus" });

        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0 && ws.readyState === WebSocket.OPEN) {
            event.data.arrayBuffer().then(buffer => ws.send(buffer));
          }
        };

        mediaRecorder.start(250);

        // Setup VAD
        audioContext = new AudioContext();
        source = audioContext.createMediaStreamSource(audioStream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 2048;
        dataArray = new Float32Array(analyser.fftSize);
        source.connect(analyser);
        detectSilence();
      };

      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        if (data.text) {
          document.getElementById("transcription").innerText = data.text;
          speakText(data.text);
        }
      };

      ws.onclose = () => {
        document.getElementById("status").textContent = "âŒ Disconnected";
      };
    }

    function stopListening() {
      if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
      }
      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.send("STOP");
      }
      if (audioStream) {
        audioStream.getTracks().forEach(track => track.stop());
      }
      if (audioContext) {
        audioContext.close();
      }
      document.getElementById("status").textContent = "ðŸ¤« Silent, waiting for reply...";
    }

    document.getElementById("startBtn").onclick = () => {
      startListening();
    };

    document.getElementById("stopBtn").onclick = () => {
      if (mediaRecorder && mediaRecorder.state !== "inactive") mediaRecorder.stop();
      if (ws && ws.readyState === WebSocket.OPEN) ws.close();
      if (audioStream) audioStream.getTracks().forEach(track => track.stop());
      if (audioContext) audioContext.close();
      document.getElementById("status").textContent = "ðŸ›‘ Stopped manually";
    };
  </script>
</body>
</html>
