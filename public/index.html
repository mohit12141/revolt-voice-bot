<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Revolt Voice Bot - Interruptible</title>
</head>
<body>
  <h1>ðŸŽ¤ Revolt Voice Bot - Auto Listen + Interrupt</h1>
  <p id="status">Click start to begin</p>
  <h2>Transcription:</h2>
  <div id="transcription" style="border:1px solid #ccc; padding:10px; min-height:40px;">
    Waiting for text...
  </div>

  <button id="startBtn">Start</button>
  <button id="stopBtn">Stop</button>
  <script>
  let ws;
  let mediaRecorder;
  let audioStream;
  let currentUtterance = null;
  let audioContext, analyser, source, dataArray;
  let silenceTimer;
  const silenceThreshold = 0.01;   // ðŸ”§ adjust mic sensitivity
  const silenceDelay = 600;        // ms of silence before stop
  let isBotSpeaking = false;

  // ðŸ”Š Speak text with browser TTS
  function speakText(text) {
    if ('speechSynthesis' in window) {
      stopSpeaking(); // clear any previous speech
      isBotSpeaking = true;

      currentUtterance = new SpeechSynthesisUtterance(text);
      currentUtterance.lang = "en-US";
      currentUtterance.rate = 1.0;
      currentUtterance.pitch = 1.0;

      currentUtterance.onstart = () => {
        document.getElementById("status").textContent = "ðŸ”Š Speaking...";
      };

      currentUtterance.onend = () => {
        console.log("âœ… Speech ended, restart listening");
        isBotSpeaking = false;
        startListening(); // restart mic after bot finishes
      };

      speechSynthesis.speak(currentUtterance);
    }
  }

  function stopSpeaking() {
    if (isBotSpeaking) {
      speechSynthesis.cancel();
      isBotSpeaking = false;
      document.getElementById("status").textContent = "ðŸŽ™ï¸ Listening...";
    }
  }

  function detectVoiceActivity() {
    if (!analyser) return;

    analyser.getFloatTimeDomainData(dataArray);
    let sumSquares = 0.0;
    for (const x of dataArray) sumSquares += x * x;
    const rms = Math.sqrt(sumSquares / dataArray.length);

    if (isBotSpeaking) {
      // ðŸŽ¤ User interrupts while bot is speaking
      if (rms > silenceThreshold * 6) {
        console.log("â›” User interrupted bot!");
        stopSpeaking();        // stop TTS immediately
        stopListening();       // stop mic session
        setTimeout(startListening, 200); // restart listening for new speech
        return;
      }
    } else {
      // ðŸ¤« Silence detection when listening
      if (rms < silenceThreshold) {
        if (!silenceTimer) {
          silenceTimer = setTimeout(stopListening, silenceDelay);
        }
      } else {
        if (silenceTimer) {
          clearTimeout(silenceTimer);
          silenceTimer = null;
        }
      }
    }

    requestAnimationFrame(detectVoiceActivity);
  }

  async function startListening() {
    if (mediaRecorder && mediaRecorder.state === "recording") return;

    ws = new WebSocket("ws://localhost:3000");

    ws.onopen = async () => {
      document.getElementById("status").textContent = "ðŸŽ™ï¸ Listening...";
      console.log("WS connected");

      audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(audioStream, { mimeType: "audio/webm;codecs=opus" });

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0 && ws.readyState === WebSocket.OPEN) {
          event.data.arrayBuffer().then(buffer => ws.send(buffer));
        }
      };

      mediaRecorder.start(250);

      // Setup analyser for VAD
      audioContext = new AudioContext();
      source = audioContext.createMediaStreamSource(audioStream);
      analyser = audioContext.createAnalyser();
      analyser.fftSize = 2048;
      dataArray = new Float32Array(analyser.fftSize);
      source.connect(analyser);
      detectVoiceActivity();
    };

    ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      if (data.text) {
        document.getElementById("transcription").innerText = data.text;
        speakText(data.text);
      }
    };

    ws.onclose = () => {
      document.getElementById("status").textContent = "âŒ Disconnected";
    };
  }

  function stopListening() {
    if (mediaRecorder && mediaRecorder.state !== "inactive") {
      mediaRecorder.stop();
    }
    if (ws && ws.readyState === WebSocket.OPEN) {
      ws.send("STOP");
    }
    if (audioStream) {
      audioStream.getTracks().forEach(track => track.stop());
    }
    if (audioContext) {
      audioContext.close();
      audioContext = null;
    }
    document.getElementById("status").textContent = "ðŸ¤« Silent, waiting for reply...";
  }

  document.getElementById("startBtn").onclick = () => {
    startListening();
  };

  document.getElementById("stopBtn").onclick = () => {
    if (mediaRecorder && mediaRecorder.state !== "inactive") mediaRecorder.stop();
    if (ws && ws.readyState === WebSocket.OPEN) ws.close();
    if (audioStream) audioStream.getTracks().forEach(track => track.stop());
    if (audioContext) audioContext.close();
    stopSpeaking();
    isBotSpeaking = false;
    document.getElementById("status").textContent = "ðŸ›‘ Stopped manually";
  };
  </script>
</body>
</html>
